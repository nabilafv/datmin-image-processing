{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to training data\n",
    "data_path = \"Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins for histogram\n",
    "bins = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-1: Color Histogram\n",
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV (Hue, Saturation, Value)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the histogram\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 2: ORB\n",
    "def fd_orb(image):\n",
    "    # Initiate STAR detector\n",
    "    vector_size = 32\n",
    "    orb = cv2.ORB_create()\n",
    "   \n",
    "    kps, des1 = orb.detectAndCompute(image, None)\n",
    "    flat_des =  des1.flatten()\n",
    "    \n",
    "    # Descriptor vector size is 64\n",
    "    needed_size = (vector_size * 64)\n",
    "    flat_des = (flat_des)[:vector_size]\n",
    "    if len(flat_des) < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "        flat_des = np.hstack([flat_des, np.zeros(needed_size - len(flat_des))])\n",
    "    \n",
    "    return flat_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels\n",
    "data_labels = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to hold feature vectors and labels\n",
    "feats = []\n",
    "labels = []\n",
    "# fixed-sizes for image\n",
    "fixed_size = tuple((500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the data sub-folders\n",
    "for data_name in data_labels:\n",
    "    # join the data path and each species folder\n",
    "    dir = os.path.join(data_path, data_name)\n",
    "    # get the current training label\n",
    "    current_label = data_name\n",
    "    \n",
    "   \n",
    "    for img in os.listdir(dir):\n",
    "        file = dir + \"/\" +img \n",
    "        image = cv2.imread(file)\n",
    "        image = cv2.resize(image, fixed_size)\n",
    "\n",
    "        ####################################\n",
    "        #Feature extraction\n",
    "        ####################################\n",
    "    \n",
    "        fv_histogram  = fd_histogram(image)\n",
    "        fv_orb = fd_orb(image)\n",
    "       \n",
    "        ###################################\n",
    "        # Concatenate global features\n",
    "        ###################################\n",
    "        feat = np.hstack([fv_histogram, fv_orb])\n",
    "\n",
    "        # update the list of labels and feature vectors\n",
    "        labels.append(current_label)\n",
    "        feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] feature vector size (42, 2560)\n",
      "[STATUS] Labels (42,)\n"
     ]
    }
   ],
   "source": [
    "feat_vector = np.array(feats)\n",
    "# get the overall feature vector size\n",
    "print (\"[STATUS] feature vector size {}\".format(feat_vector.shape))\n",
    "\n",
    "# get the overall label size\n",
    "print (\"[STATUS] Labels {}\".format(np.array(labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "(X_train, X_tes, y_train, y_test) = train_test_split(np.array(feat_vector),np.array(labels), test_size=0.1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all the machine learning models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=9, max_iter=1000)))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: Akurasi: 0.600000 F1-Score: 0.583333\n",
      "DT: Akurasi: 0.400000 F1-Score: 0.400000\n"
     ]
    }
   ],
   "source": [
    "for name, md in models:\n",
    "    model = md.fit(X_train, y_train)\n",
    "    pred = model.predict(X_tes)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    msg = \"%s: Akurasi: %f F1-Score: %f\" % (name, acc, f1)\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
